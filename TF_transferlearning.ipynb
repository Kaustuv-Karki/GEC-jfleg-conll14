{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6c28de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.9\n"
     ]
    }
   ],
   "source": [
    "!python --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b891c675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting happytransformer"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script datasets-cli.exe is installed in 'C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached happytransformer-2.4.1-py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: protobuf in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from happytransformer) (3.19.6)\n",
      "Requirement already satisfied: tqdm>=4.43 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from happytransformer) (4.64.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from happytransformer) (0.1.97)\n",
      "Requirement already satisfied: transformers>=4.4.0 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from happytransformer) (4.26.0)\n",
      "Requirement already satisfied: torch>=1.0 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from happytransformer) (1.13.1)\n",
      "Collecting datasets>=1.6.0\n",
      "  Using cached datasets-2.9.0-py3-none-any.whl (462 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (6.0)\n",
      "Collecting multiprocess\n",
      "  Using cached multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (11.0.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (3.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (0.12.0)\n",
      "Collecting responses<0.19\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: dill<0.3.7 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (0.3.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from datasets>=1.6.0->happytransformer) (21.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (1.5.3)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.3-cp310-cp310-win_amd64.whl (319 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from datasets>=1.6.0->happytransformer) (1.23.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (2023.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (2.28.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from torch>=1.0->happytransformer) (4.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.43->happytransformer) (0.4.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from transformers>=4.4.0->happytransformer) (0.13.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from transformers>=4.4.0->happytransformer) (3.9.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from transformers>=4.4.0->happytransformer) (2022.10.31)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from aiohttp->datasets>=1.6.0->happytransformer) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from aiohttp->datasets>=1.6.0->happytransformer) (2.1.1)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.8.2-cp310-cp310-win_amd64.whl (56 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->datasets>=1.6.0->happytransformer) (21.4.0)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from aiohttp->datasets>=1.6.0->happytransformer) (6.0.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from packaging->datasets>=1.6.0->happytransformer) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from requests>=2.19.0->datasets>=1.6.0->happytransformer) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from requests>=2.19.0->datasets>=1.6.0->happytransformer) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from requests>=2.19.0->datasets>=1.6.0->happytransformer) (1.26.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from pandas->datasets>=1.6.0->happytransformer) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from pandas->datasets>=1.6.0->happytransformer) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.1->pandas->datasets>=1.6.0->happytransformer) (1.16.0)\n",
      "Installing collected packages: yarl, multiprocess, async-timeout, aiosignal, responses, aiohttp, datasets, happytransformer\n",
      "Successfully installed aiohttp-3.8.3 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.9.0 happytransformer-2.4.1 multiprocess-0.70.14 responses-0.18.0 yarl-1.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install happytransformer --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b1d48c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a06fd9f9e0b842e4ba718c80a05635ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages\\huggingface_hub\\file_download.py:129: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a39c494505043468f946b16474daa88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25bbdf6c4be24e74921068f275a25b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aba013013354ce9bdee232960c00a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c581baae263b4f738c0bde4a52b36313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "02/08/2023 20:28:14 - INFO - happytransformer.happy_transformer -   Using model: cpu\n"
     ]
    }
   ],
   "source": [
    "from happytransformer import HappyTextToText\n",
    "\n",
    "happy_tt = HappyTextToText(\"T5\", \"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67b2b8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce409779a234c9cad49fe9abed3307e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.69k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d1cf096c5b4af5afad2542316ade56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/4.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0c2aaf334a4c628aefe5e7afc29af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/5.82k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset jfleg/default to C:/Users/user/.cache/huggingface/datasets/jfleg/default/1.0.0/ed4ab2367351fe31949f48849ae6732b164f0d5ea6bb5d4357ff4293ac89511b...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb7daf9c0634818aaa37b84c46cfa23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4874302964254710aa22260a7017e662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/27.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27d35ca02b84a68aac5183329e112d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/26.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d634f48401f747488c913ad7f0740b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/26.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dfb463818d04008b349db454892501d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/26.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94fc42d0a08452883ee4f867bd0a4d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/26.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80bde38c1e0345bfb0616462c7939c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf034d4b8014b139b319582f5e889b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ffb518789d4fd2b1af4bca45db6003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/27.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa96ae60d9a438fa944e196fd907784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/26.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e474cacc16f643b28276820a9764da6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/26.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4bfc7b34d3c460393b56abaff150049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/26.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977f7d6d23bf43eca6a6542278e3410b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/26.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ca7d87a63d4b00904d927981fdf705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/755 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/748 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset jfleg downloaded and prepared to C:/Users/user/.cache/huggingface/datasets/jfleg/default/1.0.0/ed4ab2367351fe31949f48849ae6732b164f0d5ea6bb5d4357ff4293ac89511b. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"jfleg\", split='validation[:]')\n",
    "\n",
    "eval_dataset = load_dataset(\"jfleg\", split='test[:]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e9db0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence', 'corrections'],\n",
       "    num_rows: 755\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92c31d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def generate_csv(csv_path, dataset):\n",
    "    with open(csv_path, 'w', newline='') as csvfile:\n",
    "        writter = csv.writer(csvfile)\n",
    "        writter.writerow([\"input\", \"target\"])\n",
    "        for case in dataset:\n",
    "     \t    # Adding the task's prefix to input \n",
    "            input_text = \"grammar: \" + case[\"sentence\"]\n",
    "            for correction in case[\"corrections\"]:\n",
    "                # a few of the cases contain blank strings. \n",
    "                if input_text and correction:\n",
    "                    writter.writerow([input_text, correction])\n",
    "                    \n",
    "\n",
    "\n",
    "generate_csv(\"train.csv\", train_dataset)\n",
    "generate_csv(\"eval.csv\", eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edd4e5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/08/2023 20:32:20 - INFO - happytransformer.happy_transformer -   Preprocessing evaluating data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/user/.cache/huggingface/datasets/csv/default-eceed22e699b2673/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22298d38987450c8bc3e0d3e16b9033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719db18049c84f75a359412eb7f0e97a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating eval split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/user/.cache/huggingface/datasets/csv/default-eceed22e699b2673/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\datasets\\download\\streaming_download_manager.py:776: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", use_auth_token=use_auth_token), **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f27920ec79142e6a01061e04914ea92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf599bdf78f4b0cbc45d4b805a83258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2988\n",
      "  Batch size = 1\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2988' max='2988' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2988/2988 06:54]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " before_result = happy_tt.eval(\"eval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fab8afa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before loss: 1.2803850173950195\n"
     ]
    }
   ],
   "source": [
    "print(\"Before loss:\", before_result.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fb4846",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/08/2023 20:39:46 - INFO - happytransformer.happy_transformer -   Preprocessing training data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/user/.cache/huggingface/datasets/csv/default-b60ddfe3a812c3ee/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f230573028d54ac4a6e4f8d900833053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1b72043f3d472c9b07d25f31b4ec22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/user/.cache/huggingface/datasets/csv/default-b60ddfe3a812c3ee/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\datasets\\download\\streaming_download_manager.py:776: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", use_auth_token=use_auth_token), **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00adf3e4e4404165b07bc8b898ae5045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c162d009b2e44cb2b5a96e1609e59193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "02/08/2023 20:39:55 - INFO - happytransformer.happy_transformer -   Training...\n",
      "PyTorch: setting up devices\n",
      "C:\\Users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3016\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1131\n",
      "  Number of trainable parameters = 222903552\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='222' max='1131' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 222/1131 20:39 < 1:25:23, 0.18 it/s, Epoch 0.59/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from happytransformer import TTTrainArgs\n",
    "\n",
    "args = TTTrainArgs(batch_size=8)\n",
    "happy_tt.train(\"train.csv\", args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3578639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_29772\\2574924190.py:5: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "TensorFlow is using GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "if tf.test.is_gpu_available():\n",
    "  print(\"TensorFlow is using GPU\")\n",
    "else:\n",
    "  print(\"TensorFlow is using CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0fb5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
